# full-link-stress-test
全链路压测

# 背景

　　全国有数千万人同时登录淘宝网，几十万人同时在一秒钟浏览商品、创建订单、支付款项。巨大的流量压力导致系统出错，订单被重复支付导致商品超卖，还有优惠券不生效导致商家与消费者怨声载道，用户投诉电话接不过来。

　　通过影子表、影子库等技术来实现全链路压测的概念，对所有的中间件、核心应用针对性的做了改造，使其具备支撑全链路压测的能力。 影子表能力可以让压测产生的写入数据全部都隔离到其他区域，不影响生产数据，应用升级中间件后就自动具备了这个能力。通过同时发起超大并发流量，对内部应用进行全链路压测。
  
# 为什么选择线上环境而不是测试环境

　　理想情况下， 如果测试环境想跟线上环境完全一致，软硬件都一致，是可以做到的。 但是为了保持完全一致，机器成本、维护成本、数据同步都需要大量的支出，所以这也要根据公司情况来衡量。如果用线上环境直接做压测的话就不需要机器与维护成本了，但是难点在于对技术的要求比较高。

# 全链路压测 的应用场景

   新系统上线场景：准确探知系统承载能力，防止刚上线被用户流量冲垮。
   
# 全链路压测 好处


　　1保障重大活动的系统稳定性

　　避免公司业务和声誉因为技术故障受到损失，**为技术团队赢得业务团队的尊重**。

　　2 精准的**容量评估**

　　帮助公司用最低的成本满足业务的性能要求

　　3 重大项目重构切换前的性能验证

　　系统重构是IT部门场景的技术更新的方法，每次上线都需要经历一段阵痛期，期间性能问题、业务故障频发，用户投诉频繁。通过全链路压测可以在正式切换前完全解决性能问题；配合自动化的用例梳理和人工验证，可以极大程度降低业务故障。两者配合使用，可以快速的渡过不稳定期，提升用户体验。

　　4 端到端的**全链路巡检**，第一时间发现故障并快递定位问题

　　常见的监控体系通过一些间接的指标来判断是否有故障发生（比如通过CPU利用率、内存使用率、应用的错误日志数量、业务单量和基线的对比等等方式），间接的方式会产生大量的误报，造成告警麻痹症，真的故障发生后不一定能第一时间引起重视。

　　通过全链路压测提供的数据隔离功能，可以在线上通过压测流量验证真实的业务接口是否能正常工作。这种方式可以直接在用户发现业务故障前，让相关人员第一时间知晓。配合链路的监测分析功能，快速定位问题应用所在。经过验证该方法在客户真实环境中比传统监控方法平均提前7分钟发现故障，告警正确率是传统告警方式的几十倍。

　　5 建立公司的性能运营体系，将运动式的性能优化演化为自发的日常性能优化

　　很多公司都有运动式或者故障驱动的性能优化经历，比如马上要双十一，总监牵头开始性能优化；有人管的时候性能表现很好，一旦没人牵头做性能优化的事情，又会有很多性能问题被暴露出来。这样的方式通过优化效率很低，投入还大。

　　6 通过全链路压测的方式，配合目标制定、绩效和工单系统。

　　自动化的全链路压测可以日常化的排查性能瓶颈，通过工单将问题直达负责人，极大的提升性能优化的效率，将性能问题控制在萌芽状态。
   
   
# 压测需要思考的几个问题

## 如何构筑压测流量？

   全链路压测需要最大程度的模拟正式业务环境下的流量，我们需要考虑到几个问题，比如请求数据如何构造，以及请求数据的多样化等。

   **人工构造**： 压测并发量不大的时候，比如并发只有几百，这种情况建议通过编写sql从数据库中导出一批线上数据，然后对这批数据进行清洗，去除敏感信息，比如客户地址、客户账号等信息，然后根据数据去准备压测脚本
   
   **录制回放**： 收集某个时间段的正常业务数据，然后通过清洗敏感信息，最后加上压测标记去运行，达到最高程度的模拟正式业务场景，确保数据的真实性、多元化，以及场景覆盖的完整性。

## 如何数据隔离？

   **流量染色**： 构造压测流量时，将压测标记加入到压测流量中进行流量染色，比如页面发起的http请求，我们会在http请求的消息头里面加入压测标记。

# 流程

生产环境压测，保证不污染线上业务和数据

![image](https://user-images.githubusercontent.com/13504729/114356108-d1b15880-9ba2-11eb-884e-af857e8f6157.png)
